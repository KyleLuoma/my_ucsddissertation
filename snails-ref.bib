
% Journals

% First the Full Name is given, then the abbreviation used in the AMS Math
% Reviews, with an indication if it could not be found there.
% Note the 2nd overwrites the 1st, so swap them if you want the full name.

 %{AMS}
 @String{AMSTrans = "American Mathematical Society Translations" }
 @String{AMSTrans = "Amer. Math. Soc. Transl." }
 @String{BullAMS = "Bulletin of the American Mathematical Society" }
 @String{BullAMS = "Bull. Amer. Math. Soc." }
 @String{ProcAMS = "Proceedings of the American Mathematical Society" }
 @String{ProcAMS = "Proc. Amer. Math. Soc." }
 @String{TransAMS = "Transactions of the American Mathematical Society" }
 @String{TransAMS = "Trans. Amer. Math. Soc." }

 %ACM
 @String{CACM = "Communications of the {ACM}" }
 @String{CACM = "Commun. {ACM}" }
 @String{CompServ = "Comput. Surveys" }
 @String{JACM = "J. ACM" }
 @String{ACMMathSoft = "{ACM} Transactions on Mathematical Software" }
 @String{ACMMathSoft = "{ACM} Trans. Math. Software" }
 @String{SIGNUM = "{ACM} {SIGNUM} Newsletter" }
 @String{SIGNUM = "{ACM} {SIGNUM} Newslett." }

 @String{AmerSocio = "American Journal of Sociology" }
 @String{AmerStatAssoc = "Journal of the American Statistical Association" }
 @String{AmerStatAssoc = "J. Amer. Statist. Assoc." }
 @String{ApplMathComp = "Applied Mathematics and Computation" }
 @String{ApplMathComp = "Appl. Math. Comput." }
 @String{AmerMathMonthly = "American Mathematical Monthly" }
 @String{AmerMathMonthly = "Amer. Math. Monthly" }
 @String{BIT = "{BIT}" }
 @String{BritStatPsych = "British Journal of Mathematical and Statistical
          Psychology" }
 @String{BritStatPsych = "Brit. J. Math. Statist. Psych." }
 @String{CanMathBull = "Canadian Mathematical Bulletin" }
 @String{CanMathBull = "Canad. Math. Bull." }
 @String{CompApplMath = "Journal of Computational and Applied Mathematics" }
 @String{CompApplMath = "J. Comput. Appl. Math." }
 @String{CompPhys = "Journal of Computational Physics" }
 @String{CompPhys = "J. Comput. Phys." }
 @String{CompStruct = "Computers and Structures" }
 @String{CompStruct = "Comput. \& Structures" }
 @String{CompJour = "The Computer Journal" }
 @String{CompJour = "Comput. J." }
 @String{CompSysSci = "Journal of Computer and System Sciences" }
 @String{CompSysSci = "J. Comput. System Sci." }
 @String{Computing = "Computing" }
 @String{ContempMath = "Contemporary Mathematics" }
 @String{ContempMath = "Contemp. Math." }
 @String{Crelle = "Crelle's Journal" }
 @String{GiornaleMath = "Giornale di Mathematiche" }
 @String{GiornaleMath = "Giorn. Mat." } % didn't find in AMS MR., ibid.

 %IEEE
 @String{Computer = "{IEEE} Computer" }
 @String{IEEETransComp = "{IEEE} Transactions on Computers" }
 @String{IEEETransComp = "{IEEE} Trans. Comput." }
 @String{IEEETransAC = "{IEEE} Transactions on Automatic Control" }
 @String{IEEETransAC = "{IEEE} Trans. Automat. Control" }
 @String{IEEESpec = "{IEEE} Spectrum" } % didn't find in AMS MR
 @String{ProcIEEE = "Proceedings of the {IEEE}" }
 @String{ProcIEEE = "Proc. {IEEE}" } % didn't find in AMS MR
 @String{IEEETransAeroElec = "{IEEE} Transactions on Aerospace and Electronic
     Systems" }
 @String{IEEETransAeroElec = "{IEEE} Trans. Aerospace Electron. Systems" }

 @String{IMANumerAna = "{IMA} Journal of Numerical Analysis" }
 @String{IMANumerAna = "{IMA} J. Numer. Anal." }
 @String{InfProcLet = "Information Processing Letters" }
 @String{InfProcLet = "Inform. Process. Lett." }
 @String{InstMathApp = "Journal of the Institute of Mathematics and
     its Applications" }
 @String{InstMathApp = "J. Inst. Math. Appl." }
 @String{IntControl = "International Journal of Control" }
 @String{IntControl = "Internat. J. Control" }
 @String{IntNumerEng = "International Journal for Numerical Methods in
     Engineering" }
 @String{IntNumerEng = "Internat. J. Numer. Methods Engrg." }
 @String{IntSuper = "International Journal of Supercomputing Applications" }
 @String{IntSuper = "Internat. J. Supercomputing Applic." } % didn't find
%% in AMS MR
 @String{Kibernetika = "Kibernetika" }
 @String{JResNatBurStand = "Journal of Research of the National Bureau
     of Standards" }
 @String{JResNatBurStand = "J. Res. Nat. Bur. Standards" }
 @String{LinAlgApp = "Linear Algebra and its Applications" }
 @String{LinAlgApp = "Linear Algebra Appl." }
 @String{MathAnaAppl = "Journal of Mathematical Analysis and Applications" }
 @String{MathAnaAppl = "J. Math. Anal. Appl." }
 @String{MathAnnalen = "Mathematische Annalen" }
 @String{MathAnnalen = "Math. Ann." }
 @String{MathPhys = "Journal of Mathematical Physics" }
 @String{MathPhys = "J. Math. Phys." }
 @String{MathComp = "Mathematics of Computation" }
 @String{MathComp = "Math. Comp." }
 @String{MathScand = "Mathematica Scandinavica" }
 @String{MathScand = "Math. Scand." }
 @String{TablesAidsComp = "Mathematical Tables and Other Aids to Computation" }
 @String{TablesAidsComp = "Math. Tables Aids Comput." }
 @String{NumerMath = "Numerische Mathematik" }
 @String{NumerMath = "Numer. Math." }
 @String{PacificMath = "Pacific Journal of Mathematics" }
 @String{PacificMath = "Pacific J. Math." }
 @String{ParDistComp = "Journal of Parallel and Distributed Computing" }
 @String{ParDistComp = "J. Parallel and Distrib. Comput." } % didn't find
%% in AMS MR
 @String{ParComputing = "Parallel Computing" }
 @String{ParComputing = "Parallel Comput." }
 @String{PhilMag = "Philosophical Magazine" }
 @String{PhilMag = "Philos. Mag." }
 @String{ProcNAS = "Proceedings of the National Academy of Sciences
                    of the USA" }
 @String{ProcNAS = "Proc. Nat. Acad. Sci. U. S. A." }
 @String{Psychometrika = "Psychometrika" }
 @String{QuartMath = "Quarterly Journal of Mathematics, Oxford, Series (2)" }
 @String{QuartMath = "Quart. J. Math. Oxford Ser. (2)" }
 @String{QuartApplMath = "Quarterly of Applied Mathematics" }
 @String{QuartApplMath = "Quart. Appl. Math." }
 @String{RevueInstStat = "Review of the International Statisical Institute" }
 @String{RevueInstStat = "Rev. Inst. Internat. Statist." }

 %SIAM
 @String{JSIAM = "Journal of the Society for Industrial and Applied
     Mathematics" }
 @String{JSIAM = "J. Soc. Indust. Appl. Math." }
 @String{JSIAMB = "Journal of the Society for Industrial and Applied
     Mathematics, Series B, Numerical Analysis" }
 @String{JSIAMB = "J. Soc. Indust. Appl. Math. Ser. B Numer. Anal." }
 @String{SIAMAlgMeth = "{SIAM} Journal on Algebraic and Discrete Methods" }
 @String{SIAMAlgMeth = "{SIAM} J. Algebraic Discrete Methods" }
 @String{SIAMAppMath = "{SIAM} Journal on Applied Mathematics" }
 @String{SIAMAppMath = "{SIAM} J. Appl. Math." }
 @String{SIAMComp = "{SIAM} Journal on Computing" }
 @String{SIAMComp = "{SIAM} J. Comput." }
 @String{SIAMMatrix = "{SIAM} Journal on Matrix Analysis and Applications" }
 @String{SIAMMatrix = "{SIAM} J. Matrix Anal. Appl." }
 @String{SIAMNumAnal = "{SIAM} Journal on Numerical Analysis" }
 @String{SIAMNumAnal = "{SIAM} J. Numer. Anal." }
 @String{SIAMReview = "{SIAM} Review" }
 @String{SIAMReview = "{SIAM} Rev." }
 @String{SIAMSciStat = "{SIAM} Journal on Scientific and Statistical
     Computing" }
 @String{SIAMSciStat = "{SIAM} J. Sci. Statist. Comput." }

 @String{SoftPracExp = "Software Practice and Experience" }
 @String{SoftPracExp = "Software Prac. Experience" } % didn't find in AMS MR
 @String{StatScience = "Statistical Science" }
 @String{StatScience = "Statist. Sci." }
 @String{Techno = "Technometrics" }
 @String{USSRCompMathPhys = "{USSR} Computational Mathematics and Mathematical
     Physics" }
 @String{USSRCompMathPhys = "{U. S. S. R.} Comput. Math. and Math. Phys." }
 @String{VLSICompSys = "Journal of {VLSI} and Computer Systems" }
 @String{VLSICompSys = "J. {VLSI} Comput. Syst." }
 @String{ZAngewMathMech = "Zeitschrift fur Angewandte Mathematik und
     Mechanik" }
 @String{ZAngewMathMech = "Z. Angew. Math. Mech." }
 @String{ZAngewMathPhys = "Zeitschrift fur Angewandte Mathematik und Physik" }
 @String{ZAngewMathPhys = "Z. Angew. Math. Phys." }

% Publishers % ================================================= |

 @String{Academic = "Academic Press" }
 @String{ACMPress = "{ACM} Press" }
 @String{AdamHilger = "Adam Hilger" }
 @String{AddisonWesley = "Addison-Wesley" }
 @String{AllynBacon = "Allyn and Bacon" }
 @String{AMS = "American Mathematical Society" }
 @String{Birkhauser = "Birkha{\"u}ser" }
 @String{CambridgePress = "Cambridge University Press" }
 @String{Chelsea = "Chelsea" }
 @String{ClaredonPress = "Claredon Press" }
 @String{DoverPub = "Dover Publications" }
 @String{Eyolles = "Eyolles" }
 @String{HoltRinehartWinston = "Holt, Rinehart and Winston" }
 @String{Interscience = "Interscience" }
 @String{JohnsHopkinsPress = "The Johns Hopkins University Press" }
 @String{JohnWileySons = "John Wiley and Sons" }
 @String{Macmillan = "Macmillan" }
 @String{MathWorks = "The Math Works Inc." }
 @String{McGrawHill = "McGraw-Hill" }
 @String{NatBurStd = "National Bureau of Standards" }
 @String{NorthHolland = "North-Holland" }
 @String{OxfordPress = "Oxford University Press" }  %address Oxford or London?
 @String{PergamonPress = "Pergamon Press" }
 @String{PlenumPress = "Plenum Press" }
 @String{PrenticeHall = "Prentice-Hall" }
 @String{SIAMPub = "{SIAM} Publications" }
 @String{Springer = "Springer-Verlag" }
 @String{TexasPress = "University of Texas Press" }
 @String{VanNostrand = "Van Nostrand" }
 @String{WHFreeman = "W. H. Freeman and Co." }

%Entries


% Language models:

@article{li2023starcoder,
      title={StarCoder: may the source be with you!}, 
      author={Raymond Li and Loubna Ben Allal and Yangtian Zi and Niklas Muennighoff and Denis Kocetkov and Chenghao Mou and Marc Marone and Christopher Akiki and Jia Li and Jenny Chim and Qian Liu and Evgenii Zheltonozhskii and Terry Yue Zhuo and Thomas Wang and Olivier Dehaene and Mishig Davaadorj and Joel Lamy-Poirier and João Monteiro and Oleh Shliazhko and Nicolas Gontier and Nicholas Meade and Armel Zebaze and Ming-Ho Yee and Logesh Kumar Umapathi and Jian Zhu and Benjamin Lipkin and Muhtasham Oblokulov and Zhiruo Wang and Rudra Murthy and Jason Stillerman and Siva Sankalp Patel and Dmitry Abulkhanov and Marco Zocca and Manan Dey and Zhihan Zhang and Nour Fahmy and Urvashi Bhattacharyya and Wenhao Yu and Swayam Singh and Sasha Luccioni and Paulo Villegas and Maxim Kunakov and Fedor Zhdanov and Manuel Romero and Tony Lee and Nadav Timor and Jennifer Ding and Claire Schlesinger and Hailey Schoelkopf and Jan Ebert and Tri Dao and Mayank Mishra and Alex Gu and Jennifer Robinson and Carolyn Jane Anderson and Brendan Dolan-Gavitt and Danish Contractor and Siva Reddy and Daniel Fried and Dzmitry Bahdanau and Yacine Jernite and Carlos Muñoz Ferrandis and Sean Hughes and Thomas Wolf and Arjun Guha and Leandro von Werra and Harm de Vries},
      year={2023},
      eprint={2305.06161},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@article{10.1145/3654930,
author = {Li, Haoyang and Zhang, Jing and Liu, Hanbing and Fan, Ju and Zhang, Xiaokang and Zhu, Jun and Wei, Renjie and Pan, Hongyan and Li, Cuiping and Chen, Hong},
title = {CodeS: Towards Building Open-source Language Models for Text-to-SQL},
year = {2024},
issue_date = {June 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {2},
number = {3},
url = {https://doi.org/10.1145/3654930},
doi = {10.1145/3654930},
abstract = {Language models have shown promising performance on the task of translating natural language questions into SQL queries (Text-to-SQL). However, most of the state-of-the-art (SOTA) approaches rely on powerful yet closed-source large language models (LLMs), such as ChatGPT and GPT-4, which may have the limitations of unclear model architectures, data privacy risks, and expensive inference overheads. To address the limitations, we introduce CodeS, a series of pre-trained language models with parameters ranging from 1B to 15B, specifically designed for the text-to-SQL task. CodeS is a fully open-source language model, which achieves superior accuracy with much smaller parameter sizes. This paper studies the research challenges in building CodeS. To enhance the SQL generation abilities of CodeS, we adopt an incremental pre-training approach using a specifically curated SQL-centric corpus. Based on this, we address the challenges of schema linking and rapid domain adaptation through strategic prompt construction and a bi-directional data augmentation technique. We conduct comprehensive evaluations on multiple datasets, including the widely used Spider benchmark, the newly released BIRD benchmark, robustness-diagnostic benchmarks such as Spider-DK, Spider-Syn, Spider-Realistic, and Dr.Spider, as well as two real-world datasets created for financial and academic applications. The experimental results show that our CodeS achieves new SOTA accuracy and robustness on nearly all challenging text-to-SQL benchmarks.},
journal = {Proc. ACM Manag. Data},
month = may,
articleno = {127},
numpages = {28},
keywords = {language model, natural language interface for databases, text-to-SQL}
}

@article{10.1145/3605943,
author = {Min, Bonan and Ross, Hayley and Sulem, Elior and Veyseh, Amir Pouran Ben and Nguyen, Thien Huu and Sainz, Oscar and Agirre, Eneko and Heintz, Ilana and Roth, Dan},
title = {Recent Advances in Natural Language Processing via Large Pre-Trained Language Models: A Survey},
year = {2023},
issue_date = {February 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {56},
number = {2},
issn = {0360-0300},
url = {https://doi.org/10.1145/3605943},
doi = {10.1145/3605943},
abstract = {Large, pre-trained language models (PLMs) such as BERT and GPT have drastically changed the Natural Language Processing (NLP) field. For numerous NLP tasks, approaches leveraging PLMs have achieved state-of-the-art performance. The key idea is to learn a generic, latent representation of language from a generic task once, then share it across disparate NLP tasks. Language modeling serves as the generic task, one with abundant self-supervised text available for extensive training. This article presents the key fundamental concepts of PLM architectures and a comprehensive view of the shift to PLM-driven NLP techniques. It surveys work applying the pre-training then fine-tuning, prompting, and text generation approaches. In addition, it discusses PLM limitations and suggested directions for future research.},
journal = {ACM Comput. Surv.},
month = {sep},
articleno = {30},
numpages = {40},
keywords = {Large language models, neural networks, generative AI, foundational models}
}

@misc{dbrx,
      title={Introducing DBRX: A New State-of-the-Art Open LLM},
      author={The Mosaic Research Team},
      year={2024},
      howpublished = {\url{https://www.databricks.com/blog/introducing-dbrx-new-state-art-open-llm}}
}

@misc{snowflakearctic,
      title={Snowflake Arctic: The Best LLM for Enterprise AI - Efficiently Intelligent, Truly Open},
      author={The Snowflake Research Team},
      year={2024},
      howpublished = {\url{https://www.snowflake.com/blog/arctic-open-efficient-foundation-language-models-snowflake/}},
}

@techreport{anil2023palm,
      title={PaLM 2 Technical Report}, 
      author={PaLM 2 Team},
      year={2023},
      eprint={2305.10403},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@misc{phind2022phindcodellama,
  title={Phind-CodeLlama-34B-v2},
  author={Phind},
  year={2023},
  howpublished={\url{https://huggingface.co/Phind/Phind-CodeLlama-34B-v2}}
}

%TODO: Drop everythin after Gemini Team
@misc{geminiteam2024gemini15,
      title={Gemini 1.5: Unlocking multimodal understanding across millions of tokens of context}, 
      author={Gemini Team},
      year={2024},
      eprint={2403.05530},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@misc{geminiteam2024gemini,
      title={Gemini: A Family of Highly Capable Multimodal Models}, 
      author={Gemini Team},
      year={2024},
      eprint={2312.11805},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@misc{gemmateam2024gemma,
      title={Gemma: Open Models Based on Gemini Research and Technology}, 
      author={Gemma Team},
      year={2024},
      eprint={2403.08295},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@misc{devlin2019bert,
      title={BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding}, 
      author={Jacob Devlin and Ming-Wei Chang and Kenton Lee and Kristina Toutanova},
      year={2019},
      eprint={1810.04805},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@misc{openai-chatgpt-blog-post,
  title={ChatGPT: Optimizing Language Models for Dialogue},
  author={OpenAI},
  howpublished={\url{https://openai.com/blog/chatgpt/}},
  year={[2022]}
}

@misc{openai-nltosql-prompt,
  author={OpenAI},
  title={Natural language to SQL},
  howpublished={\url{https://platform.openai.com/examples/default-sql-translate}},
  year={2023},
  note={Last accessed on 2023-10-26}
}

@misc{openai-api-pricing,
  author={OpenAI},
  title={OpenAI API Pricing},
  howpublished={\url{https://openai.com/pricing/}},
  year={2023},
  note={Last accessed on 2023-10-26}
}

@misc{openai-api-documentation,
  author={OpenAI},
  title={OpenAI API Documentation},
  howpublished={\url{https://platform.openai.com/docs/guides/gpt}},
  year={2023},
  note={Last accessed on 2023-10-30}
}

@misc{openai-api-finetuning,
  author={OpenAI},
  title={Fine-tuning the API for your use case},
  howpublished={\url{https://platform.openai.com/docs/guides/fine-tuning}},
  year={2023},
  note={Last accessed on 2023-12-27}
}

@misc{openai-tokenizer,
  author={OpenAI},
  title={OpenAI Tokenizer},
  howpublished={\url{https://github.com/openai/tiktoken}},
  year={2023},
  note={Last accessed on 2023-10-30}
}

@article{Clark-2022,
    author = {Clark, Jonathan H. and Garrette, Dan and Turc, Iulia and Wieting, John},
    title = {Canine: Pre-training an Efficient Tokenization-Free Encoder for Language Representation},
    journal = {Transactions of the Association for Computational Linguistics},
    year = {2022},
    volume = {10},
    pages = {73--91},
    doi = {10.1162/tacl_a_00448},
    url = {https://doi.org/10.1162%2Ftacl_a_00448},
    publisher = {MIT Press}
}

@misc{roziere2023code,
      title={Code Llama: Open Foundation Models for Code}, 
      author={Baptiste Rozière and Jonas Gehring and Fabian Gloeckle and Sten Sootla and Itai Gat and Xiaoqing Ellen Tan and Yossi Adi and Jingyu Liu and Tal Remez and Jérémy Rapin and Artyom Kozhevnikov and Ivan Evtimov and Joanna Bitton and Manish Bhatt and Cristian Canton Ferrer and Aaron Grattafiori and Wenhan Xiong and Alexandre Défossez and Jade Copet and Faisal Azhar and Hugo Touvron and Louis Martin and Nicolas Usunier and Thomas Scialom and Gabriel Synnaeve},
      year={2023},
      eprint={2308.12950},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@inproceedings{kwon2023efficient,
  title={Efficient Memory Management for Large Language Model Serving with PagedAttention},
  author={Woosuk Kwon and Zhuohan Li and Siyuan Zhuang and Ying Sheng and Lianmin Zheng and Cody Hao Yu and Joseph E. Gonzalez and Hao Zhang and Ion Stoica},
  booktitle={Proceedings of the ACM SIGOPS 29th Symposium on Operating Systems Principles},
  year={2023}
}



% Model usage limitations
% https://www.gsa.gov/directives-library/security-policy-for-generative-artificial-intelligence-ai-large-language-models-llms
@misc{gsa-llm-directive,
  title={Security Policy for Generative Artificial Intelligence (AI) Large Language Models (LLMs)},
  author={{General Services Administration}},
  howpublished={\url{https://www.gsa.gov/directives-library/security-policy-for-generative-artificial-intelligence-ai-large-language-models-llms}},
  number={CIO IL-23-01},
  status={Active},
  signatureDate={06/09/2023},
  expirationDate={06/30/2024},
  year={2023},
  note={Last accessed on 2024-05-28}
}

% Schema linking:

@INPROCEEDINGS{10096170,
  author={Hari Krishnan Parthasarathi, Sree and Zeng, Lu and Hakkani-Tür, Dilek},
  booktitle={ICASSP 2023 - 2023 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)}, 
  title={Conversational Text-to-SQL: An Odyssey into State-of-the-Art and Challenges Ahead}, 
  year={2023},
  volume={},
  number={},
  pages={1-5},
  doi={10.1109/ICASSP49357.2023.10096170}}

@INPROCEEDINGS{10023434,
  author={Zeng, Lu and Parthasarathi, Sree Hari Krishnan and Hakkani-Tur, Dilek},
  booktitle={2022 IEEE Spoken Language Technology Workshop (SLT)}, 
  title={N-Best Hypotheses Reranking for Text-to-SQL Systems}, 
  year={2023},
  volume={},
  number={},
  pages={663-670},
  doi={10.1109/SLT54892.2023.10023434}}


@inproceedings{cao-etal-2021-lgesql,
    title = "{LGESQL}: Line Graph Enhanced Text-to-{SQL} Model with Mixed Local and Non-Local Relations",
    author = "Cao, Ruisheng  and
      Chen, Lu  and
      Chen, Zhi  and
      Zhao, Yanbin  and
      Zhu, Su  and
      Yu, Kai",
    booktitle = "Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 1: Long Papers)",
    month = aug,
    year = "2021",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2021.acl-long.198",
    doi = "10.18653/v1/2021.acl-long.198",
    pages = "2541--2555",
    abstract = "This work aims to tackle the challenging heterogeneous graph encoding problem in the text-to-SQL task. Previous methods are typically node-centric and merely utilize different weight matrices to parameterize edge types, which 1) ignore the rich semantics embedded in the topological structure of edges, and 2) fail to distinguish local and non-local relations for each node. To this end, we propose a Line Graph Enhanced Text-to-SQL (LGESQL) model to mine the underlying relational features without constructing meta-paths. By virtue of the line graph, messages propagate more efficiently through not only connections between nodes, but also the topology of directed edges. Furthermore, both local and non-local relations are integrated distinctively during the graph iteration. We also design an auxiliary task called graph pruning to improve the discriminative capability of the encoder. Our framework achieves state-of-the-art results (62.8{\%} with Glove, 72.0{\%} with Electra) on the cross-domain text-to-SQL benchmark Spider at the time of writing.",
}

@inproceedings{wang2020rat-sql,
author = {Wang, Bailin and Shin, Richard and Liu, Xiaodong and Polozov, Alex and Richardson, Matthew},
title = {RAT-SQL: Relation-Aware Schema Encoding and Linking for Text-to-SQL Parsers},
booktitle = {ACL 2020},
year = {2020},
month = {June},
abstract = {When translating natural language questions into SQL queries to answer questions from a database, contemporary semantic parsing models struggle to generalize to unseen database schemas. The generalization challenge lies in (a) encoding the database relations in an accessible way for the semantic parser, and (b) modeling alignment between database columns and their mentions in a given query. We present a unified framework, based on the relation-aware self-attention mechanism, to address schema encoding, schema linking, and feature representation within a text-to-SQL encoder. On the challenging Spider dataset this framework boosts the exact match accuracy to 53.7%, compared to 47.4% for the state-of-the-art model unaugmented with BERT embeddings. In addition, we observe qualitative improvements in the model's understanding of schema linking and alignment.},
url = {https://www.microsoft.com/en-us/research/publication/rat-sql-relation-aware-schema-encoding-and-linking-for-text-to-sql-parsers/},
}

@inproceedings{10.1145/3534678.3539305,
author = {Wang, Lihan and Qin, Bowen and Hui, Binyuan and Li, Bowen and Yang, Min and Wang, Bailin and Li, Binhua and Sun, Jian and Huang, Fei and Si, Luo and Li, Yongbin},
title = {Proton: Probing Schema Linking Information from Pre-Trained Language Models for Text-to-SQL Parsing},
year = {2022},
isbn = {9781450393850},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3534678.3539305},
doi = {10.1145/3534678.3539305},
abstract = {The importance of building text-to-SQL parsers which can be applied to new databases has long been acknowledged, and a critical step to achieve this goal is schema linking, i.e., properly recognizing mentions of unseen columns or tables when generating SQLs. In this work, we propose a novel framework to elicit relational structures from large-scale pre-trained language models (PLMs) via a probing procedure based on Poincar\'{e} distance metric, and use the induced relations to augment current graph-based parsers for better schema linking. Compared with commonly-used rule-based methods for schema linking, we found that probing relations can robustly capture semantic correspondences, even when surface forms of mentions and entities differ. Moreover, our probing procedure is entirely unsupervised and requires no additional parameters. Extensive experiments show that our framework sets new state-of-the-art performance on three benchmarks. We empirically verify that our probing procedure can indeed find desired relational structures through qualitative analysis.},
booktitle = {Proceedings of the 28th ACM SIGKDD Conference on Knowledge Discovery and Data Mining},
pages = {1889–1898},
numpages = {10},
keywords = {semantic parsing, text-to-sql parsing, knowledge probing},
location = {Washington DC, USA},
series = {KDD '22}
}

@misc{li2023resdsql,
author = {Li, Haoyang and Zhang, Jing and Li, Cuiping and Chen, Hong},
title = {RESDSQL: decoupling schema linking and skeleton parsing for text-to-SQL},
year = {2023},
isbn = {978-1-57735-880-0},
publisher = {AAAI Press},
url = {https://doi.org/10.1609/aaai.v37i11.26535},
doi = {10.1609/aaai.v37i11.26535},
abstract = {One of the recent best attempts at Text-to-SQL is the pre-trained language model. Due to the structural property of the SQL queries, the seq2seq model takes the responsibility of parsing both the schema items (i.e., tables and columns) and the skeleton (i.e., SQL keywords). Such coupled targets increase the difficulty of parsing the correct SQL queries especially when they involve many schema items and logic operators. This paper proposes a ranking-enhanced encoding and skeleton-aware decoding framework to decouple the schema linking and the skeleton parsing. Specifically, for a seq2seq encoder-decode model, its encoder is injected by the most relevant schema items instead of the whole unordered ones, which could alleviate the schema linking effort during SQL parsing, and its decoder first generates the skeleton and then the actual SQL query, which could implicitly constrain the SQL parsing. We evaluate our proposed framework on Spider and its three robustness variants: Spider-DK, Spider-Syn, and Spider-Realistic. The experimental results show that our framework delivers promising performance and robustness.},
booktitle = {Proceedings of the Thirty-Seventh AAAI Conference on Artificial Intelligence and Thirty-Fifth Conference on Innovative Applications of Artificial Intelligence and Thirteenth Symposium on Educational Advances in Artificial Intelligence},
articleno = {1466},
numpages = {9},
series = {AAAI'23/IAAI'23/EAAI'23}
}


% Naturalness:
@article{10.1162/COLI_a_00168,
    author = {Kuhn, Tobias},
    title = "{A Survey and Classification of Controlled Natural Languages}",
    journal = {Computational Linguistics},
    volume = {40},
    number = {1},
    pages = {121-170},
    year = {2014},
    month = {03},
    abstract = "{What is here called controlled natural language (CNL) has traditionally been given many different names. Especially during the last four decades, a wide variety of such languages have been designed. They are applied to improve communication among humans, to improve translation, or to provide natural and intuitive representations for formal notations. Despite the apparent differences, it seems sensible to put all these languages under the same umbrella. To bring order to the variety of languages, a general classification scheme is presented here. A comprehensive survey of existing English-based CNLs is given, listing and describing 100 languages from 1930 until today. Classification of these languages reveals that they form a single scattered cloud filling the conceptual space between natural languages such as English on the one end and formal languages such as propositional logic on the other. The goal of this article is to provide a common terminology and a common model for CNL, to contribute to the understanding of their general nature, to provide a starting point for researchers interested in the area, and to help developers to make design decisions.}",
    issn = {0891-2017},
    doi = {10.1162/COLI_a_00168},
    url = {https://doi.org/10.1162/COLI\_a\_00168},
    eprint = {https://direct.mit.edu/coli/article-pdf/40/1/121/1812691/coli\_a\_00168.pdf},
}



% Schema naming guidelines:

@misc{db2-schema-naming-guidelines,
  author={IBM},
  title={Limits in Db2 for z/OS},
  howpublished={\url{https://www.ibm.com/docs/en/db2-for-zos/11?topic=sql-limits-in-db2-zos}},
  note={Last accessed on 2023-11-07}
}

@misc{oracle-schema-naming-guidelines,
  author={Oracle},
  title={Database Object Names and Qualifiers},
  howpublished={\url{https://docs.oracle.com/en/database/oracle/oracle-database/19/sqlrf/Database-Object-Names-and-Qualifiers.html}},
  year={2024},
  month={November},
  day={13},
  note={Last accessed on 2025-01-04}
}

@misc{oracle-schema-naming-guidelines-2,
  author={Oracle},
  title={Table Naming Standards and Conventions},
  howpublished={\url{https://docs.oracle.com/cd/E92917_01/PDF/8.1.x.x/common/HTML/DM_Naming/2_Table_and_Column_Naming_Standards.htm}},
  year={2024},
  month={November},
  day={13},
  note={Last accessed on 2025-01-04}
}

%https://documentation.sas.com/doc/en/lrcon/9.4/p18cdcs4v5wd2dn1q0x296d3qek6.htm
@misc{sas-names,
  author={SAS},
  title={Names in the SAS Language},
  howpublished={\url{https://documentation.sas.com/doc/en/lrcon/9.4/p18cdcs4v5wd2dn1q0x296d3qek6.htm}},
  note={Last accessed on 2023-11-07}
}

@misc{csharp-naming-convention,
  author={Pankaj Kumar Choudhary},
  title={Naming Conventions in SQL},
  howpublished={\url{https://www.c-sharpcorner.com/UploadFile/f0b2ed/what-is-naming-convention/}},
  year={2022},
  month={December},
  day={27},
  note={Last accessed on 2024-01-01}
}

@misc{oracle-naming-convention,
  author={Oracle},
  title={Database Object Names and Qualifiers},
  howpublished={\url{https://docs.oracle.com/en/database/oracle/oracle-database/19/sqlrf/Database-Object-Names-and-Qualifiers.html}},
  note={Last accessed on 2024-01-01}
}

@misc{stackoverflow-naming-convention,
  author={StackOverflow},
  title={Database, Table and Column Naming Conventions?},
  howpublished={\url{https://stackoverflow.com/questions/7662/database-table-and-column-naming-conventions}},
  note={Last accessed on 2024-01-01}
}

@misc{sqlserver-naming-convention,
  author={Konstantin Taranov},
  title={SQL Server Name Convention and T-SQL Programming Style},
  howpublished={\url{https://github.com/ktaranov/sqlserver-kit/blob/master/SQL%20Server%20Name%20Convention%20and%20T-SQL%20Programming%20Style.md}},
  note={Last accessed on 2024-01-01}
}

@misc{inbo-naming-convention,
  author={Gert Van Spaendonk, Jo Loos, Frederic Piesschaert},
  title={Database naming conventions},
  howpublished={\url{https://inbo.github.io/tutorials/tutorials/database_conventions/}},
  note={Last accessed on 2024-01-01}
}


@inproceedings{10.1145/3183519.3183529,
author = {Sharma, Tushar and Fragkoulis, Marios and Rizou, Stamatia and Bruntink, Magiel and Spinellis, Diomidis},
title = {Smelly Relations: Measuring and Understanding Database Schema Quality},
year = {2018},
isbn = {9781450356596},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3183519.3183529},
doi = {10.1145/3183519.3183529},
booktitle = {Proceedings of the 40th International Conference on Software Engineering: Software Engineering in Practice},
pages = {55–64},
numpages = {10},
keywords = {software maintenance, code smells, technical debt, software quality, database schema smells, antipatterns},
location = {Gothenburg, Sweden},
series = {ICSE-SEIP '18}
}


%Schema mapping
@INPROCEEDINGS{4061430,
  author={Xu, Zhuoming and Zhang, Shichao and Dong, Yisheng},
  booktitle={2006 IEEE/WIC/ACM International Conference on Web Intelligence (WI 2006 Main Conference Proceedings)(WI'06)}, 
  title={Mapping between Relational Database Schema and OWL Ontology for Deep Annotation}, 
  year={2006},
  volume={},
  number={},
  pages={548-552},
  doi={10.1109/WI.2006.114}}

@INPROCEEDINGS{7396620,
  author={Hazber, Mohamed A. G. and Li, Ruixuan and Zhang, Yuxi and Xu, Guandong},
  booktitle={2015 12th Web Information System and Application Conference (WISA)}, 
  title={An Approach for Mapping Relational Database into Ontology}, 
  year={2015},
  volume={},
  number={},
  pages={120-125},
  doi={10.1109/WISA.2015.25}}


@inproceedings{nameguess,
    title = "{N}ame{G}uess: Column Name Expansion for Tabular Data",
    author = "Zhang, Jiani  and
      Shen, Zhengyuan  and
      Srinivasan, Balasubramaniam  and
      Wang, Shen  and
      Rangwala, Huzefa  and
      Karypis, George",
    editor = "Bouamor, Houda  and
      Pino, Juan  and
      Bali, Kalika",
    booktitle = "Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing",
    month = dec,
    year = "2023",
    address = "Singapore",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2023.emnlp-main.820",
    doi = "10.18653/v1/2023.emnlp-main.820",
    pages = "13276--13290",
    abstract = "Recent advances in large language models have revolutionized many sectors, including the database industry. One common challenge when dealing with large volumes of tabular data is the pervasive use of abbreviated column names, which can negatively impact performance on various data search, access, and understanding tasks. To address this issue, we introduce a new task, called NameGuess, to expand column names (used in database schema) as a natural language generation problem. We create a training dataset of 384K abbreviated-expanded column pairs using a new data fabrication method and a human-annotated evaluation benchmark that includes 9.2K examples from real-world tables. To tackle the complexities associated with polysemy and ambiguity in NameGuess, we enhance auto-regressive language models by conditioning on table content and column header names {--} yielding a fine-tuned model (with 2.7B parameters) that matches human performance. Furthermore, we conduct a comprehensive analysis (on multiple LLMs) to validate the effectiveness of table content in NameGuess and identify promising future opportunities. Code has been made available at https://github.com/amazon-science/nameguess.",
}

% Benchmarks:

@inproceedings{floratou2024nl2sql,
  author = {Floratou, Avrilia and Psallidas, Fotis and Zhao, Fuheng and Deep, Shaleen and Hagleither, Gunther and Tan, Wangda and Cahoon, Joyce and Alotaibi, Rana and Henkel, Jordan and Singla, Abhik and Van Grootel, Alex and Chow, Brandon and Deng, Kai and Lin, Katherine and Campos, Marcos and Emani, Venkatesh and Pandit, Vivek and Shnayder, Victor and Wang, Wenjing and Curino, Carlo},
  title = {NL2SQL is a solved problem... Not!},
  booktitle = {Proceedings of the CIDRDB 2024 Conference},
  year = {2024},
  month = {January},
  url = {https://www.cidrdb.org/cidr2024/papers/p74-floratou.pdf}
}


%MT teql
@article{10.14778/3494124.3494139,
author = {Ma, Pingchuan and Wang, Shuai},
title = {MT-Teql: Evaluating and Augmenting Neural NLIDB on Real-World Linguistic and Schema Variations},
year = {2021},
issue_date = {November 2021},
publisher = {VLDB Endowment},
volume = {15},
number = {3},
issn = {2150-8097},
url = {https://doi.org/10.14778/3494124.3494139},
doi = {10.14778/3494124.3494139},
abstract = {Natural Language Interface to Database (NLIDB) translates human utterances into SQL queries and enables database interactions for non-expert users. Recently, neural network models have become a major approach to implementing NLIDB. However, neural NLIDB faces challenges due to variations in natural language and database schema design. For instance, one user intent or database conceptual model can be expressed in various forms. However, existing benchmarks, using hold-out datasets, cannot provide thorough understanding of how good neural NLIDBs really are in real-world situations and its robustness against such variations. A key difficulty is to annotate SQL queries for inputs under real-world variations, requiring considerable manual effort and expert knowledge.To systematically assess the robustness of neural NLIDBs without extensive manual effort, we propose MT-Teql, a unified framework to benchmark NLIDBs against real-world language and schema variations. Inspired by recent advances in DBMS metamorphic testing, MT-Teql implements semantics-preserving transformations on utterances and database schemas to generate their variants. NLIDBs can thus be examined for robustness utilizing utterances/schemas and their variants without requiring manual intervention.We benchmarked nine neural NLIDBs using 62,430 inputs and identified 15,433 defects. We analyzed potential root causes of defects and conducted a user study to show how MT-Teql can assist developers to systematically assess NLIDBs. We further show that the transformed (error-triggering) inputs can be used to augment popular NLIDBs and eliminate 46.5\%(±5.0\%) errors made by them without compromising their accuracy on standard benchmarks. We summarize lessons from this study that can provide insights to select and design NLIDBs that fit particular usage scenarios.},
journal = {Proc. VLDB Endow.},
month = {nov},
pages = {569–582},
numpages = {14}
}

@inproceedings{Yu&al.18c,
  title     = {Spider: A Large-Scale Human-Labeled Dataset for Complex and Cross-Domain Semantic Parsing and Text-to-SQL Task},
  author    = {Tao Yu and Rui Zhang and Kai Yang and Michihiro Yasunaga and Dongxu Wang and Zifan Li and James Ma and Irene Li and Qingning Yao and Shanelle Roman and Zilin Zhang and Dragomir Radev},
  booktitle = {Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing},
  address   = "Brussels, Belgium",
  publisher = "Association for Computational Linguistics",
  year      = 2018
}

%Spider-syn
@inproceedings{gan-etal-2021-towards,
    title = "Towards Robustness of Text-to-{SQL} Models against Synonym Substitution",
    author = "Gan, Yujian  and
      Chen, Xinyun  and
      Huang, Qiuping  and
      Purver, Matthew  and
      Woodward, John R.  and
      Xie, Jinxia  and
      Huang, Pengsheng",
    editor = "Zong, Chengqing  and
      Xia, Fei  and
      Li, Wenjie  and
      Navigli, Roberto",
    booktitle = "Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 1: Long Papers)",
    month = aug,
    year = "2021",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2021.acl-long.195",
    doi = "10.18653/v1/2021.acl-long.195",
    pages = "2505--2515",
    abstract = "Recently, there has been significant progress in studying neural networks to translate text descriptions into SQL queries. Despite achieving good performance on some public benchmarks, existing text-to-SQL models typically rely on the lexical matching between words in natural language (NL) questions and tokens in table schemas, which may render the models vulnerable to attacks that break the schema linking mechanism. In this work, we investigate the robustness of text-to-SQL models to synonym substitution. In particular, we introduce Spider-Syn, a human-curated dataset based on the Spider benchmark for text-to-SQL translation. NL questions in Spider-Syn are modified from Spider, by replacing their schema-related words with manually selected synonyms that reflect real-world question paraphrases. We observe that the accuracy dramatically drops by eliminating such explicit correspondence between NL questions and table schemas, even if the synonyms are not adversarially selected to conduct worst-case attacks. Finally, we present two categories of approaches to improve the model robustness. The first category of approaches utilizes additional synonym annotations for table schemas by modifying the model input, while the second category is based on adversarial training. We demonstrate that both categories of approaches significantly outperform their counterparts without the defense, and the first category of approaches are more effective.",
}

%Spider-realistic
@inproceedings{deng2021structure-grounded,
author = {Deng, Xiang and Awadallah, Ahmed and Meek, Chris and Polozov, Alex and Sun, Huan and Richardson, Matthew},
title = {Structure-Grounded Pretraining for Text-to-SQL},
booktitle = {NAACL 2021},
year = {2021},
month = {June},
abstract = {Learning to capture text-table alignment is essential for table related tasks like text-to-SQL. The model needs to correctly recognize natural language references to columns and values and to ground them in the given database schema. In this paper, we present a novel weakly supervised Structure-Grounded pretraining framework (StruG) for text-to-SQL that can effectively learn to capture text-table alignment based on a parallel text-table corpus. We identify a set of novel prediction tasks: column grounding, value grounding and column-value mapping, and train them using weak supervision without requiring complex SQL annotation. Additionally, to evaluate the model under a more realistic setting, we create a new evaluation set Spider-Realistic based on Spider with explicit mentions of column names removed, and adopt two existing single-database text-to-SQL datasets. StruG significantly outperforms BERT-LARGE on Spider and the realistic evaluation sets, while bringing consistent improvement on the large-scale WikiSQL benchmark.},
url = {https://www.microsoft.com/en-us/research/publication/structure-grounded-pretraining-for-text-to-sql/},
}

%Bird
@misc{li2023llm,
author = {Li, Jinyang and Hui, Binyuan and Qu, Ge and Yang, Jiaxi and Li, Binhua and Li, Bowen and Wang, Bailin and Qin, Bowen and Geng, Ruiying and Huo, Nan and Zhou, Xuanhe and Ma, Chenhao and Li, Guoliang and Chang, Kevin C.C. and Huang, Fei and Cheng, Reynold and Li, Yongbin},
title = {Can LLM already serve as a database interface? a big bench for large-scale database grounded text-to-SQLs},
year = {2024},
publisher = {Curran Associates Inc.},
address = {Red Hook, NY, USA},
abstract = {Text-to-SQL parsing, which aims at converting natural language questions into executable SQLs, has gained increasing attention in recent years. In particular, GPT-4 and Claude-2 have shown impressive results in this task. However, most of the prevalent benchmarks, i.e., Spider, and WikiSQL, focus on database schema with few rows of database values leaving the gap between academic study and real-world applications. To mitigate this gap, we present BIRD, a BIg bench for laRge-scale Database grounded in text-to-SQL tasks, containing 12,751 text-to-SQL pairs and 95 databases with a total size of 33.4 GB, spanning 37 professional domains. Our emphasis on database values highlights the new challenges of dirty and noisy database values, external knowledge grounding between NL questions and database values, and SQL efficiency, particularly in the context of massive databases. To solve these problems, text-to-SQL models must feature database value comprehension in addition to semantic parsing. The experimental results demonstrate the significance of database values in generating accurate text-to-SQLs for big databases. Furthermore, even the most effective text-to-SQL models, i.e. GPT-4, only achieve 54.89\% in execution accuracy, which is still far from the human result of 92.96\%, proving that challenges still stand. We also provide an efficiency analysis to offer insights into generating text-to-efficient-SQLs that are beneficial to industries. We believe that BIRD will contribute to advancing real-world applications of text-to-SQL research. The leaderboard and source code are available: https://bird-bench.github.io/.},
booktitle = {Proceedings of the 37th International Conference on Neural Information Processing Systems},
articleno = {1835},
numpages = {28},
location = {New Orleans, LA, USA},
series = {NIPS '23}
}

@inproceedings{49288,
title	= {Exploring Unexplored Generalization Challenges for  Cross-Database Semantic Parsing},
author	= {Alane Laughlin Suhr and Kenton Lee and Ming-Wei Chang and Pete Shaw},
year	= {2020},
booktitle	= {ACL 2020}
}


%Spider leaderboard 10 26 2023
%1, 2
@misc{gao2023texttosql,
author = {Gao, Dawei and Wang, Haibin and Li, Yaliang and Sun, Xiuyu and Qian, Yichen and Ding, Bolin and Zhou, Jingren},
title = {Text-to-SQL Empowered by Large Language Models: A Benchmark Evaluation},
year = {2024},
issue_date = {January 2024},
publisher = {VLDB Endowment},
volume = {17},
number = {5},
issn = {2150-8097},
url = {https://doi.org/10.14778/3641204.3641221},
doi = {10.14778/3641204.3641221},
abstract = {Large language models (LLMs) have emerged as a new paradigm for Text-to-SQL task. However, the absence of a systematical benchmark inhibits the development of designing effective, efficient and economic LLM-based Text-to-SQL solutions. To address this challenge, in this paper, we first conduct a systematical and extensive comparison over existing prompt engineering methods, including question representation, example selection and example organization, and with these experimental results, we elaborate their pros and cons. Based on these findings, we propose a new integrated solution, named DAIL-SQL, which refreshes the Spider leaderboard with 86.6\% execution accuracy and sets a new bar.To explore the potential of open-source LLM, we investigate them in various scenarios, and further enhance their performance with supervised fine-tuning. Our explorations highlight open-source LLMs' potential in Text-to-SQL, as well as the advantages and disadvantages of the supervised fine-tuning. Additionally, towards an efficient and economic LLM-based Text-to-SQL solution, we emphasize the token efficiency in prompt engineering and compare the prior studies under this metric. We hope that our work provides a deeper understanding of Text-to-SQL with LLMs, and inspires further investigations and broad applications.},
journal = {Proc. VLDB Endow.},
month = may,
pages = {1132–1145},
numpages = {14}
}

%3
@inproceedings{pourreza2023dinsql,
author = {Pourreza, Mohammadreza and Rafiei, Davood},
title = {DIN-SQL: decomposed in-context learning of text-to-SQL with self-correction},
year = {2024},
publisher = {Curran Associates Inc.},
address = {Red Hook, NY, USA},
abstract = {There is currently a significant gap between the performance of fine-tuned models and prompting approaches using Large Language Models (LLMs) on the challenging task of text-to-SQL, as evaluated on datasets such as Spider. To improve the performance of LLMs in the reasoning process, we study how decomposing the task into smaller sub-tasks can be effective. In particular, we show that breaking down the generation problem into sub-problems and feeding the solutions of those sub-problems into LLMs can be an effective approach for significantly improving their performance. Our experiments with three LLMs show that this approach consistently improves their simple few-shot performance by roughly 10\%, pushing the accuracy of LLMs towards SOTA or surpassing it. On the holdout test set of Spider, the SOTA, in terms of execution accuracy, was 79.9 and the new SOTA at the time of this writing using our approach is 85.3. Our approach with in-context learning beats many heavily fine-tuned models by at least 5\%. Additionally, when evaluated on the BIRD benchmark, our approach achieved an execution accuracy of 55.9\%, setting a new SOTA on its holdout test set.},
booktitle = {Proceedings of the 37th International Conference on Neural Information Processing Systems},
articleno = {1577},
numpages = {10},
location = {New Orleans, LA, USA},
series = {NIPS '23}
}

%5
@misc{dong2023c3,
      title={C3: Zero-shot Text-to-SQL with ChatGPT}, 
      author={Xuemei Dong and Chao Zhang and Yuhang Ge and Yuren Mao and Yunjun Gao and lu Chen and Jinshu Lin and Dongfang Lou},
      year={2023},
      eprint={2307.07306},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@misc{rai2023improving,
      title={Improving Generalization in Language Model-Based Text-to-SQL Semantic Parsing: Two Simple Semantic Boundary-Based Techniques}, 
      author={Daking Rai and Bailin Wang and Yilun Zhou and Ziyu Yao},
      year={2023},
      eprint={2305.17378},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@inproceedings{10.1609/aaai.v37i11.26536,
author = {Li, Jinyang and Hui, Binyuan and Cheng, Reynold and Qin, Bowen and Ma, Chenhao and Huo, Nan and Huang, Fei and Du, Wenyu and Si, Luo and Li, Yongbin},
title = {Graphix-T5: mixing pre-trained transformers with graph-aware layers for text-to-SQL parsing},
year = {2023},
isbn = {978-1-57735-880-0},
publisher = {AAAI Press},
url = {https://doi.org/10.1609/aaai.v37i11.26536},
doi = {10.1609/aaai.v37i11.26536},
abstract = {The task of text-to-SQL parsing, which aims at converting natural language questions into executable SQL queries, has garnered increasing attention in recent years. One of the major challenges in text-to-SQL parsing is domain generalization, i.e., how to generalize well to unseen databases. Recently, the pre-trained text-to-text transformer model, namely T5, though not specialized for text-to-SQL parsing, has achieved state-of-the-art performance on standard benchmarks targeting domain generalization. In this work, we explore ways to further augment the pre-trained T5 model with specialized components for text-to-SQL parsing. Such components are expected to introduce structural inductive bias into text-to-SQL parsers thus improving model's capacity on (potentially multi-hop) reasoning, which is critical for generating structure-rich SQLs. To this end, we propose a new architecture GRAPHIX-T5, a mixed model with the standard pre-trained transformer model augmented by specially-designed graph-aware layers. Extensive experiments and analysis demonstrate the effectiveness of GRAPHIX-T5 across four text-to-SQL benchmarks: SPIDER, SYN, REALISTIC and DK. GRAPHIX-T5 surpass all other T5-based parsers with a significant margin, achieving new state-of-the-art performance. Notably, GRAPHIX-T5-large reaches performance superior to the original T5-large by 5.7\% on exact match (EM) accuracy and 6.6\% on execution accuracy (EX). This even outperforms the T5-3B by 1.2\% on EM and 1.5\% on EX.},
booktitle = {Proceedings of the Thirty-Seventh AAAI Conference on Artificial Intelligence and Thirty-Fifth Conference on Innovative Applications of Artificial Intelligence and Thirteenth Symposium on Educational Advances in Artificial Intelligence},
articleno = {1467},
numpages = {9},
series = {AAAI'23/IAAI'23/EAAI'23}
}


% Evaluation Methodologies
@inproceedings{finegan-dollak-etal-2018-improving,
    title = "Improving Text-to-{SQL} Evaluation Methodology",
    author = "Finegan-Dollak, Catherine  and
      Kummerfeld, Jonathan K.  and
      Zhang, Li  and
      Ramanathan, Karthik  and
      Sadasivam, Sesh  and
      Zhang, Rui  and
      Radev, Dragomir",
    booktitle = "Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
    month = jul,
    year = "2018",
    address = "Melbourne, Australia",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/P18-1033",
    doi = "10.18653/v1/P18-1033",
    pages = "351--360",
    abstract = "To be informative, an evaluation must measure how well systems generalize to realistic unseen data. We identify limitations of and propose improvements to current evaluations of text-to-SQL systems. First, we compare human-generated and automatically generated questions, characterizing properties of queries necessary for real-world applications. To facilitate evaluation on multiple datasets, we release standardized and improved versions of seven existing datasets and one new text-to-SQL dataset. Second, we show that the current division of data into training and test sets measures robustness to variations in the way questions are asked, but only partially tests how well systems generalize to new queries; therefore, we propose a complementary dataset split for evaluation of future work. Finally, we demonstrate how the common practice of anonymizing variables during evaluation removes an important challenge of the task. Our observations highlight key difficulties, and our methodology enables effective measurement of future development.",
}

%Data sets

@inproceedings{doehmen2024schemapile,
  title = "SchemaPile: A Large Collection of Relational Database Schemas",
  author = "Doehmen, Till and Geacu, Radu and Hulsebos, Madelon and Schelter, Sebastian",
  booktitle = "Proceedings of the ACM SIGMOD International Conference on Management of Data",
  year = "2024"
}

@misc{nps-irma-portal,
    title = "{NPS} {IRMA} Portal",
    howpublished = "\url{https://irma.nps.gov/Portal/}",
    note = "Accessed: April 2023"
}

@misc{pilb-dataset,
    title = "{Pacific Island Network Landbird Monitoring Dataset}",
    howpublished = "\url{https://irma.nps.gov/DataStore/Reference/Profile/2300107}",
    note = "Accessed: April 2023",
    author = "Judge, Seth and Kozar, Kevin",
    year = "2023",
    publisher = "National Park Service",
    address = "Fort Collins, CO",
    doi = "10.57830/2300107"
}

@misc{assateague-herp,
    title = "{Field Data for Assateague Island National Seashore Amphibian and Reptile Inventory}",
    howpublished = "\url{https://irma.nps.gov/DataStore/Reference/Profile/2236826}",
    note = "Accessed: April 2023",
    author = "Cook, Robert",
    year = "2016",
    publisher = "National Park Service",
}

@misc{gsmnp-atbi,
    title = "{Great Smoky Mountains All Taxa Biodiversity Inventory (ATBI) Plot Vegetation Monitoring Database}",
    howpublished = "\url{https://irma.nps.gov/DataStore/Reference/Profile/2221324}",
    note = "Accessed: April 2023",
    author = "Evans, Thomas",
    year = "2015",
    publisher = "National Park Service",
}

@misc{craters-of-the-moon-wildlife,
    title = "{Wildlife Observations Database: Craters of the Moon National Monument and Preserve 1921-2021}",
    howpublished = "\url{https://irma.nps.gov/DataStore/Reference/Profile/2192964}",
    note = "Accessed: April 2023",
    author = "Stefanic, Charles",
    year = "2021",
    publisher = "National Park Service",
}

@misc{klamath-inventory,
    title = "{Exotic and Invasive Plants Monitoring Database}",
    howpublished = "\url{https://irma.nps.gov/DataStore/Reference/Profile/2288667}",
    note = "Accessed: April 2023",
    author = "Klamath Inventory and Monitoring Network",
    year = "2021",
    publisher = "National Park Service",
}

%Muirhead I. Northern Great Plains Fire Management: FFI Database
@misc{ngp-fire,
    title = "{Northern Great Plains Fire Management: FFI Database}",
    howpublished = "\url{https://irma.nps.gov/DataStore/Reference/Profile/2297267}",
    note = "Accessed: April 2023",
    author = "Muirhead, Ian",
    year = "2021",
    publisher = "National Park Service",
}

@misc{nysed-report-card,
    title = "{Report Card Database 2021-22}",
    howpublished = "\url{https://data.nysed.gov/files/essa/21-22/SRC2022.zip}",
    note = "Accessed: May 2023",
    year = "2022",
    publisher = "New York State Education Department",
}

@misc{sap-erpref,
    title = "{SAP TABLES}",
    howpublished = "\url{https://sap.erpref.com/}",
    note = "Accessed: June 2023"
}

@misc{sap-demo,
    title = "Localized Demo Databases Now Available for SAP Business One 10.0 FP 2011",
    howpublished = "\url{https://blogs.sap.com/2021/01/29/localized-demo-databases-now-available-for-sap-business-one-10.0-fp-2011/}",
    note = "Accessed: April 2023",
    author = "Poujois, Marie-Laurence",
    year = "2021",
    month = "January"
}

@misc{crash-investigation-sampling-system,
    title = "Crash Investigation Sampling System 2021 analytical user’s manual",
    note = "Accessed: April 2023",
    author = "Radja, G. A. and Noh, E.-Y. and Zhang, F.",
    year = "2022",
    month = "December",
    publisher = "National Highway Traffic Safety Administration",
    number = "DOT HS 813 398"
}

@misc{ncsa2022overview,
  title = {Overview of the 2021 Crash Investigation Sampling System},
  author = {{National Center for Statistics and Analysis}},
  year = {2022},
  month = {December},
  note = {Traffic Safety Facts Research Note. Report No. DOT HS 813 397},
  organization = {National Highway Traffic Safety Administration},
  url = {https://crashstats.nhtsa.dot.gov/Api/Public/ViewPublication/813397},
}

%Software and Libraries
@inproceedings{Parr2014,
    author = {Parr, Terence and Harwell, Sam and Fisher, Kathleen},
    title = {Adaptive LL(*) Parsing: The Power of Dynamic Analysis},
    year = {2014},
    isbn = {9781450325851},
    publisher = {Association for Computing Machinery},
    address = {New York, NY, USA},
    url = {https://doi.org/10.1145/2660193.2660202},
    doi = {10.1145/2660193.2660202},
    abstract = {Despite the advances made by modern parsing strategies such as PEG, LL(*), GLR, and GLL, parsing is not a solved problem. Existing approaches suffer from a number of weaknesses, including difficulties supporting side-effecting embedded actions, slow and/or unpredictable performance, and counter-intuitive matching strategies. This paper introduces the ALL(*) parsing strategy that combines the simplicity, efficiency, and predictability of conventional top-down LL(k) parsers with the power of a GLR-like mechanism to make parsing decisions. The critical innovation is to move grammar analysis to parse-time, which lets ALL(*) handle any non-left-recursive context-free grammar. ALL(*) is O(n4) in theory but consistently performs linearly on grammars used in practice, outperforming general strategies such as GLL and GLR by orders of magnitude. ANTLR 4 generates ALL(*) parsers and supports direct left-recursion through grammar rewriting. Widespread ANTLR 4 use (5000 downloads/month in 2013) provides evidence that ALL(*) is effective for a wide variety of applications.},
    booktitle = {Proceedings of the 2014 ACM International Conference on Object Oriented Programming Systems Languages and Applications},
    pages = {579–598},
    numpages = {20},
    keywords = {grammar, peg, all(*), nondeterministic parsing, ll(*), augmented transition networks, gll, dfa, glr},
    location = {Portland, Oregon, USA},
    series = {OOPSLA '14}
}

@misc{antlrgrammarsv4,
  title = {grammars-v4},
  year = {2022},
  publisher = {GitHub},
  journal = {GitHub repository},
  howpublished = {\url{https://github.com/antlr/grammars-v4}},
  commit = {6a084712f0875d3508cdeb2926a95b1e7b524400}
}

%Luoma, Kyle and Kumar, Arun

@techreport{techreport,
  title={SNAILS: Schema Naturalness Assessments for Improved LLM Systems},
  author={Luoma, Kyle and Kumar, Arun},
  year = {2024},
  source = {https://github.com/ADALabUCSD/ADALabUCSD.github.io/blob/master/papers/TR_2025_SNAILS.pdf},
  address = {La Jolla, CA, USA},
}


%Ambiguity

@inproceedings{
huang2023data,
title={Data Ambiguity Strikes Back: How Documentation Improves {GPT}'s Text-to-{SQL}},
author={Zezhou Huang and Pavan Kalyan Damalapati and Eugene Wu},
booktitle={NeurIPS 2023 Second Table Representation Learning Workshop},
year={2023},
url={https://openreview.net/forum?id=FflKTuIRTD}
}

@INPROCEEDINGS{10555063,
  author={Papicchio, Simone and Papotti, Paolo and Cagliero, Luca},
  booktitle={2024 IEEE 40th International Conference on Data Engineering Workshops (ICDEW)}, 
  title={Evaluating Ambiguous Questions in Semantic Parsing}, 
  year={2024},
  volume={},
  number={},
  pages={338-342},
  keywords={Representation learning;Structured Query Language;Natural languages;Semantics;Pipelines;Data models;Robustness;Tabular Representation Learning;Semantic Parsing;Text2SQL;Data-Ambiguity;NL2SQL;Large Language Models},
  doi={10.1109/ICDEW61823.2024.00050}}


%Prompting
@misc{nan2023enhancingfewshottexttosqlcapabilities,
      title={Enhancing Few-shot Text-to-SQL Capabilities of Large Language Models: A Study on Prompt Design Strategies}, 
      author={Linyong Nan and Yilun Zhao and Weijin Zou and Narutatsu Ri and Jaesung Tae and Ellen Zhang and Arman Cohan and Dragomir Radev},
      year={2023},
      eprint={2305.12586},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2305.12586}, 
}

%Question writing
@inproceedings{10.5555/3666122.3667470,
author = {Papicchio, Simone and Papotti, Paolo and Cagliero, Luca},
title = {QATCH: benchmarking SQL-centric tasks with table representation learning models on your data},
year = {2024},
publisher = {Curran Associates Inc.},
address = {Red Hook, NY, USA},
abstract = {Table Representation Learning (TRL) models are commonly pre-trained on large open-domain datasets comprising millions of tables and then used to address downstream tasks. Choosing the right TRL model to use on proprietary data can be challenging, as the best results depend on the content domain, schema, and data quality. Our purpose is to support end-users in testing TRL models on proprietary data in two established SQL-centric tasks, i.e., Question Answering (QA) and Semantic Parsing (SP). We present QATCH (Query-Aided TRL Checklist), a toolbox to highlight TRL models' strengths and weaknesses on relational tables unseen at training time. For an input table, QATCH automatically generates a testing checklist tailored to QA and SP. Checklist generation is driven by a SQL query engine that crafts tests of different complexity. This design facilitates inherent portability, allowing the checks to be used by alternative models. We also introduce a set of cross-task performance metrics evaluating the TRL model's performance over its output. Finally, we show how QATCH automatically generates tests for proprietary datasets to evaluate various state-of-the-art models including TAPAS, TAPEX, and CHATGPT.},
booktitle = {Proceedings of the 37th International Conference on Neural Information Processing Systems},
articleno = {1348},
numpages = {20},
location = {New Orleans, LA, USA},
series = {NIPS '23}
}